"""
JSON ë°ì´í„° í´ë¼ì´ì–¸íŠ¸ - gzip ì••ì¶• ì§€ì›
JSON íŒŒì¼ì—ì„œ ì§ì ‘ ë°ì´í„°ë¥¼ ì½ì–´ì˜¤ëŠ” ìµœì í™”ëœ í´ë¼ì´ì–¸íŠ¸
"""
import json
import gzip
import streamlit as st
from typing import Dict, List, Any, Optional
import logging
import os

logger = logging.getLogger(__name__)


class InvestSmartJSONClient:
    """InvestSmart JSON ë°ì´í„° í´ë¼ì´ì–¸íŠ¸ - ìµœì í™”ëœ ìºì‹± ë²„ì „"""
    
    def __init__(self, data_dir: str = "data"):
        self.data_dir = data_dir
        self._cache = {}  # ì¢…ëª©ë³„ ë°ì´í„° ìºì‹œ (ë¡œì»¬)
        self._processed_cache = {}  # ì²˜ë¦¬ëœ ë°ì´í„° ìºì‹œ (ë¡œì»¬)
        
        # Streamlit session_state ì´ˆê¸°í™”
        if 'json_data_cache' not in st.session_state:
            st.session_state.json_data_cache = {}
        if 'processed_data_cache' not in st.session_state:
            st.session_state.processed_data_cache = {}
        if 'cache_stats' not in st.session_state:
            st.session_state.cache_stats = {
                'cache_hits': 0,
                'cache_misses': 0,
                'total_requests': 0
            }
    
    def _get_symbol_filename(self, symbol: str, compressed: bool = True) -> str:
        """ì¢…ëª© ì‹¬ë³¼ì„ íŒŒì¼ëª…ìœ¼ë¡œ ë³€í™˜ - ì••ì¶• ì§€ì›"""
        # íŠ¹ìˆ˜ ë¬¸ìë¥¼ ì•ˆì „í•œ ë¬¸ìë¡œ ë³€í™˜
        safe_symbol = symbol.replace('^', '').replace('=', '').replace('/', '_')
        if compressed:
            return f"signals_{safe_symbol}.json.gz"
        else:
            return f"signals_{safe_symbol}.json"
    
    def _load_symbol_data(self, symbol: str) -> List[Dict]:
        """íŠ¹ì • ì¢…ëª©ì˜ JSON íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ - gzip ì••ì¶• ì§€ì›"""
        try:
            # 1. Streamlit session_stateì—ì„œ ë¨¼ì € í™•ì¸
            if symbol in st.session_state.json_data_cache:
                st.session_state.cache_stats['cache_hits'] += 1
                logger.info(f"âœ… ìºì‹œ íˆíŠ¸: {symbol}")
                return st.session_state.json_data_cache[symbol]
            
            # 2. ë¡œì»¬ ìºì‹œì—ì„œ í™•ì¸
            if symbol in self._cache:
                st.session_state.cache_stats['cache_hits'] += 1
                logger.info(f"âœ… ë¡œì»¬ ìºì‹œ íˆíŠ¸: {symbol}")
                # session_stateì—ë„ ì €ì¥
                st.session_state.json_data_cache[symbol] = self._cache[symbol]
                return self._cache[symbol]
            
            # 3. íŒŒì¼ì—ì„œ ë¡œë“œ (ì••ì¶• íŒŒì¼ ìš°ì„ , ì—†ìœ¼ë©´ ì¼ë°˜ íŒŒì¼)
            st.session_state.cache_stats['cache_misses'] += 1
            logger.info(f"ğŸ“ íŒŒì¼ì—ì„œ ë¡œë“œ: {symbol}")
            
            # ì••ì¶• íŒŒì¼ ì‹œë„
            compressed_filename = self._get_symbol_filename(symbol, compressed=True)
            compressed_file_path = os.path.join(self.data_dir, compressed_filename)
            
            # ì¼ë°˜ íŒŒì¼ ì‹œë„
            normal_filename = self._get_symbol_filename(symbol, compressed=False)
            normal_file_path = os.path.join(self.data_dir, normal_filename)
            
            data = []
            
            # ì••ì¶• íŒŒì¼ì´ ìˆìœ¼ë©´ ì••ì¶• í•´ì œë¡œ ë¡œë“œ
            if os.path.exists(compressed_file_path):
                logger.info(f"ğŸ“¦ ì••ì¶• íŒŒì¼ ë¡œë“œ: {compressed_filename}")
                with gzip.open(compressed_file_path, 'rt', encoding='utf-8') as f:
                    data = json.load(f)
            # ì¼ë°˜ íŒŒì¼ì´ ìˆìœ¼ë©´ ì¼ë°˜ ë¡œë“œ
            elif os.path.exists(normal_file_path):
                logger.info(f"ğŸ“„ ì¼ë°˜ íŒŒì¼ ë¡œë“œ: {normal_filename}")
                with open(normal_file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
            else:
                logger.warning(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {symbol}")
                return []
                
            # 4. ëª¨ë“  ìºì‹œì— ì €ì¥
            self._cache[symbol] = data
            st.session_state.json_data_cache[symbol] = data
            
            return data
            
        except Exception as e:
            logger.error(f"JSON íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {symbol}, {e}")
            return []
    
    def get_signals_data(self, symbol: str, period: str = "1y") -> Dict[str, Any]:
        """íŠ¹ì • ì¢…ëª©ì˜ ì‹ í˜¸ ë°ì´í„° ì¡°íšŒ - ìµœì í™”ëœ ìºì‹± ë²„ì „"""
        try:
            # í†µê³„ ì—…ë°ì´íŠ¸
            st.session_state.cache_stats['total_requests'] += 1
            
            # ì²˜ë¦¬ëœ ë°ì´í„° ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
            cache_key = f"{symbol}_{period}"
            if cache_key in st.session_state.processed_data_cache:
                st.session_state.cache_stats['cache_hits'] += 1
                logger.info(f"âœ… ì²˜ë¦¬ëœ ë°ì´í„° ìºì‹œ íˆíŠ¸: {symbol}")
                return st.session_state.processed_data_cache[cache_key]
            
            # ì›ë³¸ ë°ì´í„° ë¡œë“œ (ì´ë¯¸ ìµœì í™”ëœ ìºì‹± ì ìš©)
            symbol_data = self._load_symbol_data(symbol)
            
            if not symbol_data:
                return {
                    'symbol': symbol,
                    'dates': [],
                    'signals': {},
                    'indicators': {},
                    'error': 'ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
                }
            
            # ë°ì´í„° êµ¬ì¡°í™” - ìµœì í™”ëœ ë²„ì „ (í•œ ë²ˆì— ì²˜ë¦¬)
            dates = []
            stock_data = {'open': [], 'high': [], 'low': [], 'close': [], 'volume': []}
            signals_data = {
                'short_signal_v1': [], 'short_signal_v2': [], 'long_signal': [],
                'combined_signal_v1': [], 'macd_signal': [], 'momentum_color_signal': []
            }
            indicators_data = {'Final_Composite_Value': []}
            
            # í•œ ë²ˆì˜ ë£¨í”„ë¡œ ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ (ì„±ëŠ¥ ìµœì í™”)
            for item in symbol_data:
                dates.append(item['date'])
                stock_data['open'].append(item.get('open', 0))
                stock_data['high'].append(item.get('high', 0))
                stock_data['low'].append(item.get('low', 0))
                stock_data['close'].append(item.get('close', 0))
                stock_data['volume'].append(item.get('volume', 0))
                signals_data['short_signal_v1'].append(item.get('short_signal_v1', 0))
                signals_data['short_signal_v2'].append(item.get('short_signal_v2', 0))
                signals_data['long_signal'].append(item.get('long_signal', 0))
                signals_data['combined_signal_v1'].append(item.get('combined_signal_v1', 0))
                signals_data['macd_signal'].append(item.get('macd_signal', 0))
                signals_data['momentum_color_signal'].append(item.get('momentum_color_signal', 0))
                indicators_data['Final_Composite_Value'].append(item.get('fcv', 0))
            
            # ê²°ê³¼ ë°ì´í„° êµ¬ì„±
            result = {
                'symbol': symbol,
                'dates': dates,
                'data': stock_data,
                'signals': signals_data,
                'indicators': indicators_data,
                'trendlines': [],  # ì¶”ì„¸ì„  ë°ì´í„° (ë‚˜ì¤‘ì— ì¶”ê°€ ì˜ˆì •)
                'last_updated': symbol_data[-1].get('last_updated', dates[-1]) if symbol_data else None
            }
            
            # ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥
            st.session_state.processed_data_cache[cache_key] = result
            
            return result
            
        except Exception as e:
            logger.error(f"ì‹ í˜¸ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {symbol}, {e}")
            return {
                'symbol': symbol,
                'dates': [],
                'signals': {},
                'indicators': {},
                'error': f'ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}'
            }
    
    def get_available_symbols(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì¢…ëª© ëª©ë¡ ì¡°íšŒ - ìµœì í™”ëœ ì§€ì—° ë¡œë”©"""
        try:
            # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
            if 'available_symbols' in st.session_state:
                st.session_state.cache_stats['cache_hits'] += 1
                logger.info("âœ… ì¢…ëª© ëª©ë¡ ìºì‹œ íˆíŠ¸")
                return st.session_state.available_symbols
            
            # íŒŒì¼ëª…ë§Œ ì½ì–´ì„œ ë¹ ë¥´ê²Œ ì²˜ë¦¬
            symbols = []
            if os.path.exists(self.data_dir):
                # íŒŒì¼ëª… íŒ¨í„´ ë§¤í•‘ (ì„±ëŠ¥ ìµœì í™”)
                symbol_mapping = {
                    "KS11": "^KS11", "IXIC": "^IXIC", "GSPC": "^GSPC", "DJI": "^DJI",
                    "FTSE": "^FTSE", "GDAXI": "^GDAXI", "FCHI": "^FCHI", "N225": "^N225",
                    "HSI": "^HSI", "AXJO": "^AXJO", "GCF": "GC=F", "SIF": "SI=F",
                    "CLF": "CL=F", "NGF": "NG=F", "ZCF": "ZC=F", "ZSF": "ZS=F",
                    "USDKRWX": "USDKRW=X", "EURUSDX": "EURUSD=X", "GBPUSDX": "GBPUSD=X",
                    "USDJPYX": "USDJPY=X", "005930KS": "005930.KS"
                }
                
                # íŒŒì¼ëª…ë§Œ ì½ê¸° (JSON íŒŒì¼ ë‚´ìš©ì€ ì½ì§€ ì•ŠìŒ) - ì••ì¶• íŒŒì¼ ì§€ì›
                for filename in os.listdir(self.data_dir):
                    if filename.startswith("signals_") and (filename.endswith(".json") or filename.endswith(".json.gz")):
                        # íŒŒì¼ëª…ì—ì„œ ì‹¬ë³¼ ì¶”ì¶œ (ì••ì¶• íŒŒì¼ê³¼ ì¼ë°˜ íŒŒì¼ ëª¨ë‘ ì²˜ë¦¬)
                        if filename.endswith(".json.gz"):
                            symbol = filename.replace("signals_", "").replace(".json.gz", "")
                        else:
                            symbol = filename.replace("signals_", "").replace(".json", "")
                        # ë§¤í•‘ í…Œì´ë¸” ì‚¬ìš© (ì„±ëŠ¥ ìµœì í™”)
                        symbol = symbol_mapping.get(symbol, symbol)
                        symbols.append(symbol)
            
            # ì •ë ¬ ë° ìºì‹±
            symbols = sorted(symbols)
            st.session_state.available_symbols = symbols
            st.session_state.cache_stats['cache_misses'] += 1
            logger.info(f"ğŸ“ ì¢…ëª© ëª©ë¡ íŒŒì¼ì—ì„œ ë¡œë“œ: {len(symbols)}ê°œ")
            return symbols
            
        except Exception as e:
            logger.error(f"ì¢…ëª© ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_data_info(self) -> Dict[str, Any]:
        """ë°ì´í„° ì •ë³´ ì¡°íšŒ - ìµœì í™”ëœ ë²„ì „"""
        try:
            # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
            if 'data_info' in st.session_state:
                st.session_state.cache_stats['cache_hits'] += 1
                logger.info("âœ… ë°ì´í„° ì •ë³´ ìºì‹œ íˆíŠ¸")
                return st.session_state.data_info
            
            symbols = self.get_available_symbols()
            
            # ê°„ë‹¨í•œ ì •ë³´ë§Œ ì¡°íšŒ (ì „ì²´ ë°ì´í„° ë¡œë“œí•˜ì§€ ì•ŠìŒ)
            total_records = 0
            last_updated = None
            
            # íŒŒì¼ í¬ê¸°ë¡œ ëŒ€ëµì ì¸ ë ˆì½”ë“œ ìˆ˜ ì¶”ì • (ì„±ëŠ¥ ìµœì í™”)
            for symbol in symbols:
                filename = self._get_symbol_filename(symbol)
                file_path = os.path.join(self.data_dir, filename)
                if os.path.exists(file_path):
                    # íŒŒì¼ í¬ê¸°ë¡œ ëŒ€ëµì ì¸ ë ˆì½”ë“œ ìˆ˜ ì¶”ì • (JSON í‰ê·  í¬ê¸° ê¸°ì¤€)
                    file_size = os.path.getsize(file_path)
                    estimated_records = max(1, file_size // 200)  # í‰ê·  200ë°”ì´íŠ¸/ë ˆì½”ë“œ
                    total_records += estimated_records
            
            # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ëŠ” í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ì„¤ì • (ì •í™•í•œ ì‹œê°„ì€ í•„ìš”ì‹œ ê°œë³„ ì¡°íšŒ)
            last_updated = "2024-01-01"  # ê¸°ë³¸ê°’
            
            result = {
                'total_records': total_records,
                'symbols': symbols,
                'last_updated': last_updated
            }
            
            # ìºì‹œì— ì €ì¥
            st.session_state.data_info = result
            st.session_state.cache_stats['cache_misses'] += 1
            logger.info(f"ğŸ“ ë°ì´í„° ì •ë³´ íŒŒì¼ì—ì„œ ë¡œë“œ: {len(symbols)}ê°œ ì¢…ëª©")
            return result
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'total_records': 0, 'symbols': [], 'last_updated': None}
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ì¡°íšŒ"""
        try:
            stats = st.session_state.cache_stats
            total_requests = stats['total_requests']
            cache_hits = stats['cache_hits']
            cache_misses = stats['cache_misses']
            
            hit_rate = (cache_hits / total_requests * 100) if total_requests > 0 else 0
            
            return {
                'total_requests': total_requests,
                'cache_hits': cache_hits,
                'cache_misses': cache_misses,
                'hit_rate': round(hit_rate, 2),
                'cached_symbols': len(st.session_state.json_data_cache),
                'processed_cache_size': len(st.session_state.processed_data_cache)
            }
        except Exception as e:
            logger.error(f"ìºì‹œ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'total_requests': 0, 'cache_hits': 0, 'cache_misses': 0, 'hit_rate': 0}
    
    def clear_cache(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        try:
            st.session_state.json_data_cache.clear()
            st.session_state.processed_data_cache.clear()
            st.session_state.cache_stats = {
                'cache_hits': 0,
                'cache_misses': 0,
                'total_requests': 0
            }
            self._cache.clear()
            self._processed_cache.clear()
            logger.info("âœ… ëª¨ë“  ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"ìºì‹œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def compress_json_files(self) -> Dict[str, Any]:
        """JSON íŒŒì¼ë“¤ì„ gzipìœ¼ë¡œ ì••ì¶•"""
        try:
            compressed_count = 0
            total_savings = 0
            
            symbols = self.get_available_symbols()
            
            for symbol in symbols:
                # ì¼ë°˜ JSON íŒŒì¼ ê²½ë¡œ
                normal_filename = self._get_symbol_filename(symbol, compressed=False)
                normal_file_path = os.path.join(self.data_dir, normal_filename)
                
                # ì••ì¶• íŒŒì¼ ê²½ë¡œ
                compressed_filename = self._get_symbol_filename(symbol, compressed=True)
                compressed_file_path = os.path.join(self.data_dir, compressed_filename)
                
                # ì¼ë°˜ íŒŒì¼ì´ ìˆê³  ì••ì¶• íŒŒì¼ì´ ì—†ìœ¼ë©´ ì••ì¶•
                if os.path.exists(normal_file_path) and not os.path.exists(compressed_file_path):
                    try:
                        # ì›ë³¸ íŒŒì¼ í¬ê¸°
                        original_size = os.path.getsize(normal_file_path)
                        
                        # ì••ì¶• íŒŒì¼ ìƒì„±
                        with open(normal_file_path, 'rb') as f_in:
                            with gzip.open(compressed_file_path, 'wb') as f_out:
                                f_out.write(f_in.read())
                        
                        # ì••ì¶• íŒŒì¼ í¬ê¸°
                        compressed_size = os.path.getsize(compressed_file_path)
                        savings = original_size - compressed_size
                        savings_percent = (savings / original_size) * 100
                        
                        total_savings += savings
                        compressed_count += 1
                        
                        logger.info(f"ğŸ“¦ ì••ì¶• ì™„ë£Œ: {symbol} ({original_size:,} â†’ {compressed_size:,} bytes, {savings_percent:.1f}% ì ˆì•½)")
                        
                    except Exception as e:
                        logger.error(f"ì••ì¶• ì‹¤íŒ¨: {symbol}, {e}")
            
            return {
                'compressed_files': compressed_count,
                'total_savings_bytes': total_savings,
                'total_savings_mb': round(total_savings / (1024 * 1024), 2),
                'average_savings_percent': round((total_savings / (total_savings + (total_savings * 0.3))) * 100, 1) if total_savings > 0 else 0
            }
            
        except Exception as e:
            logger.error(f"JSON íŒŒì¼ ì••ì¶• ì‹¤íŒ¨: {e}")
            return {'compressed_files': 0, 'total_savings_bytes': 0, 'total_savings_mb': 0, 'average_savings_percent': 0}